{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to whatever you prefer if this doesn't work. But you will want interactivty so you can zoom\n",
    "# in and out of the map.\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "from matplotlib.colors import rgb2hex\n",
    "\n",
    "# I had issues importing basemap on mpl v3.3 due to the 'dedent' module. I downgraded to \n",
    "# v3.2 in order to import. Will maybe try rewriting code using Cartopy, since Basemap is no \n",
    "# longer supported (I think).\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Need these modules for changing directory to reference the shapefile folder\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# These are just to try some data visualizations in a 3D scatterplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/zbp18detail.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ab792923e15e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read in industry details dataset, converting zip column to string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m df1 = pd.read_csv('data/zbp18detail.txt', \n\u001b[0m\u001b[0;32m      3\u001b[0m                   \u001b[0mconverters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'zip'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                   header=0)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/zbp18detail.txt'"
     ]
    }
   ],
   "source": [
    "# Read in industry details dataset, converting zip column to string\n",
    "df1 = pd.read_csv('data/zbp18detail.txt', \n",
    "                  converters={'zip': lambda x: str(x)}, \n",
    "                  header=0)\n",
    "\n",
    "# Keep only the industry sector level data, given by naics codes in the form '11----' or similar. \n",
    "# Including lower level sectors would result in a sparse matrix.\n",
    "# For detail, see https://www.census.gov/eos/www/naics/2017NAICS/2017_NAICS_Manual.pdf (page 26)\n",
    "df1 = df1[df1['naics'].str.contains('^\\d{2}\\D{4}$')]\n",
    "\n",
    "# Drop rows with zip 99999, this is a dummy code\n",
    "df1 = df1[df1['zip'] != '99999']\n",
    "\n",
    "# The numeric columns were read as objects because they use 'N' for zeros. Coerce them to numeric data and fill NAs with zeros\n",
    "df1.iloc[:, 3:] = df1.iloc[:, 3:].apply(pd.to_numeric, errors='coerce')\n",
    "df1.fillna(0, inplace=True)\n",
    "\n",
    "# Consolidate all n>5 into a single column and drop all others. We'll just use two features, n<5 and n>5\n",
    "df1['n>5'] = df1.iloc[:, 4:].sum(axis=1)\n",
    "df1.drop(df1.columns[4:-1], axis=1, inplace=True)\n",
    "df1.drop('est', axis=1, inplace=True)\n",
    "\n",
    "# Pivot the data so we have single columns for each feature\n",
    "zip_details = df1.pivot(index='zip', columns='naics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casper.Messmann\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:643: UserWarning: merging between different levels can give an unintended result (1 levels on the left,2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Read in the industry totals dataset, converting zip column to string\n",
    "df2 = pd.read_csv('data/zbp18totals.txt', \n",
    "                  converters={'zip': lambda x: str(x)}, \n",
    "                  encoding='latin_1',\n",
    "                  header=0)\n",
    "\n",
    "# Set zip column as the index\n",
    "df2.set_index('zip', inplace=True)\n",
    "\n",
    "# Drop the row 99999, it is a dummy zip. Aslo drop columns we don't want.\n",
    "df2.drop('99999', axis=0, inplace=True)\n",
    "df2.drop(['name', 'emp_nf', 'qp1_nf', 'qp1', 'ap_nf', 'cty_name'], axis=1, inplace=True)\n",
    "\n",
    "# Merge with the zip_details dataframe from above. This throws a warning because zip_details has a column index, but it works out here.\n",
    "df2_details = df2.merge(zip_details, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by state/city in a multiindex. We will do analysis at the city level, but visualize by zip code.\n",
    "# Cities have multiple associated zip codes, but each zip code has only one city\n",
    "city = df2_details.groupby(['stabbr', 'city']).agg('sum')\n",
    "\n",
    "# Truncate 0 employee rows to 1 employee\n",
    "city['emp'].replace(0, 1, inplace=True)\n",
    "\n",
    "# Create relationship columns for each pair of metrics\n",
    "city['ap per emp'] = city['ap'] / city['emp']\n",
    "city['ap per est'] = city['ap'] / city['est']\n",
    "city['emp per est'] = city['emp'] / city['est']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the city features\n",
    "city_n = pd.DataFrame(StandardScaler().fit_transform(city))\n",
    "\n",
    "# StandardScaler returned a numpy array, so we need to set the index and column names again\n",
    "city_n.set_index(city.index, drop=False, inplace=True)\n",
    "city_n.columns = [\"n_{}\".format(x) for x in city.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the feature vector for Farminton, MI. Reshaping in order to pass to cosine similarity function\n",
    "sim_vec = np.array(city_n.loc['MI', 'FARMINGTON']).reshape(1, -1)\n",
    "\n",
    "# Get cosine similarity between FARMINGTON and every other city and add that as a new column\n",
    "sims = cosine_similarity(sim_vec, city_n)\n",
    "city_n['sim'] = sims.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-b2b9509230b6>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  zips['zips'] = zips.index\n"
     ]
    }
   ],
   "source": [
    "# Make a new df with just zip, city, state info from our original df2\n",
    "zips = df2[['city', 'stabbr']]\n",
    "\n",
    "# Switch the index to match city_n and move zip codes to a column. I get a warning here, but I think it's a false positive. Ignoring.\n",
    "zips['zips'] = zips.index\n",
    "zips.set_index(['stabbr', 'city'], inplace=True)\n",
    "\n",
    "# Merge the dataframes so we get the zip codes for each state/city again\n",
    "zips = zips.merge(city_n, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the colormap\n",
    "cmap = cm.get_cmap('coolwarm')\n",
    "\n",
    "# The similarity values are from [-1, 1], so we first normalize to [0,1]\n",
    "zips['n_sim'] = zips['sim'].apply(lambda x: (x+1)/2)\n",
    "\n",
    "# Get the zip code colors and turn into a dictionary of form 'zip: color'\n",
    "zip_colors = cmap(zips['n_sim'])\n",
    "zip_colors = dict(zip(zips['zips'], zip_colors))\n",
    "\n",
    "# We'll just show MI on the map, but some surrounding states will also show up (MI, WI, IL)\n",
    "# Getting just the zip codes and colors for those states\n",
    "mapzips = list(zips.loc[['MI', 'WI', 'IL']]['zips'])\n",
    "mapzips_colors = {z: zip_colors[z] for z in mapzips}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to folder with shapefile data for drawing the map\n",
    "us_shape_file_dir = 'data/cb_2018_us_zcta510_500k/'\n",
    "os.chdir(us_shape_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabdfee16d704292be174b939862ecd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ProjError",
     "evalue": "x, y, z, and time must be same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProjError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2880db3c30d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Creating the basemap object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m m = Basemap(llcrnrlon=lowerlon,\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mllcrnrlat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlowerlat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0murcrnrlon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupperlon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mpl_toolkits\\basemap\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, llcrnrlon, llcrnrlat, urcrnrlon, urcrnrlat, llcrnrx, llcrnry, urcrnrx, urcrnry, width, height, projection, resolution, area_thresh, rsphere, ellps, lat_ts, lat_1, lat_2, lat_0, lon_0, lon_1, lon_2, o_lon_p, o_lat_p, k_0, no_rot, suppress_ticks, satellite_height, boundinglat, fix_aspect, anchor, celestial, round, epsg, ax)\u001b[0m\n\u001b[0;32m   1125\u001b[0m             \u001b[1;31m# replace coastsegs with line segments (instead of polygons)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoastsegs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1127\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readboundarydata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gshhs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mas_polygons\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1128\u001b[0m         \u001b[1;31m# create geos Polygon structures for land areas.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m         \u001b[1;31m# currently only used in is_land method.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mpl_toolkits\\basemap\\__init__.py\u001b[0m in \u001b[0;36m_readboundarydata\u001b[1;34m(self, name, as_polygons)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                                     \u001b[1;31m# transformation from lat/lon to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m                                     \u001b[1;31m# map projection coordinates.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m                                     \u001b[0mbx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m                                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mas_polygons\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                                         \u001b[0mpolygons\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mpl_toolkits\\basemap\\__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, y, inverse)\u001b[0m\n\u001b[0;32m   1186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_dg2rad\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0myy\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0myy\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mxout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprojtran\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcelestial\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minverse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mpl_toolkits\\basemap\\proj.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kw)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0moutxy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_proj4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m             \u001b[0moutx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mouty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_proj4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minverse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprojection\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'merc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mill'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gall'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyproj\\proj.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, longitude, latitude, inverse, errcheck, radians)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mdirection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransformDirection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFORWARD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         return self.transform(\n\u001b[0m\u001b[0;32m    183\u001b[0m             \u001b[0mxx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0myy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyproj\\transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, xx, yy, zz, tt, radians, errcheck, direction)\u001b[0m\n\u001b[0;32m    486\u001b[0m             \u001b[0mintime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;31m# call pj_transform.  inx,iny,inz buffers modified in place.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         self._transformer._transform(\n\u001b[0m\u001b[0;32m    489\u001b[0m             \u001b[0minx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m             \u001b[0miny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpyproj/_transformer.pyx\u001b[0m in \u001b[0;36mpyproj._transformer._Transformer._transform\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mProjError\u001b[0m: x, y, z, and time must be same size"
     ]
    }
   ],
   "source": [
    "# Creating the plot for Michigan\n",
    "plt.figure(figsize=(9, 5.5))\n",
    "\n",
    "# Setting the map's bounding coordinates\n",
    "lowerlon = -90.5\n",
    "upperlon = -81\n",
    "lowerlat = 41.689\n",
    "upperlat = 47.5\n",
    "\n",
    "# Creating the basemap object\n",
    "m = Basemap(llcrnrlon=lowerlon,\n",
    "            llcrnrlat=lowerlat,\n",
    "            urcrnrlon=upperlon,\n",
    "            urcrnrlat=upperlat,\n",
    "            resolution='c',\n",
    "            projection='lcc',\n",
    "            lat_0=lowerlat,\n",
    "            lat_1=upperlat,\n",
    "            lon_0=lowerlon,\n",
    "            lon_1=upperlon)\n",
    "\n",
    "# Read in the shapefile and pull out zip code info\n",
    "shp_info = m.readshapefile(os.path.basename('/cb_2018_us_zcta510_500k'), 'states', drawbounds=True)\n",
    "zip_info = m.states_info\n",
    "\n",
    "# These loops are for getting our zip code list and colors, but we need to get them in the right order\n",
    "# with the shapefile. I imagine there is a much better way of doing this, because I don't really want \n",
    "# to loop through every US zip code.\n",
    "ziplist = []\n",
    "colors = {}\n",
    "\n",
    "for d in zip_info:\n",
    "    iterzip = d[\"ZCTA5CE10\"]\n",
    "    if iterzip in mapzips:\n",
    "        colors[iterzip] = mapzips_colors[iterzip][:3]\n",
    "    ziplist.append(iterzip)\n",
    "    \n",
    "for nshape, seg in enumerate(m.states):\n",
    "    i, j = zip(*seg)\n",
    "    if ziplist[nshape] in mapzips:\n",
    "        color = rgb2hex(colors[ziplist[nshape]])\n",
    "        edgecolor = '#FFFFFF'\n",
    "        plt.fill(i, j, color, edgecolor=edgecolor)\n",
    "\n",
    "# Just adding a colorbar to the plot with descriptive labels\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=mpl.colors.Normalize(vmin=0, vmax=1))\n",
    "mm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "mm.set_array([0, 1])\n",
    "cbar = plt.colorbar(mm, ticks=np.arange(0, 2, 1), orientation='vertical')\n",
    "cbar.set_ticklabels(['Lest Similar', 'Most Similar'])\n",
    "\n",
    "plt.gca().axis('off')\n",
    "plt.title('Economic Similarity to Farmington, MI by City Zip Codes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stabbr  city       \n",
       "MI      FARMINGTON     1.000000\n",
       "OH      WESTERVILLE    0.927645\n",
       "MI      TROY           0.926306\n",
       "MN      MINNEAPOLIS    0.909998\n",
       "MI      NOVI           0.909105\n",
       "OH      DUBLIN         0.907356\n",
       "FL      TAMPA          0.907048\n",
       "MD      ROCKVILLE      0.905961\n",
       "CA      CARLSBAD       0.897065\n",
       "AL      HUNTSVILLE     0.896974\n",
       "Name: sim, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of curiosity, thes are the 10 most similar cities to Farmington, MI accoring to our methodology\n",
    "zips['sim'].drop_duplicates().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6c1d79a4bb4b9c8b2b47567743e44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell is ONLY for visualizing the data using PCA. We'll just do cities in MI.\n",
    "# First dedupe the the zips df, because each city has multiple zips, now we only have city data \n",
    "# Then we can apply PCA and make a scatterplot. The dot colors represent similarity to Farmington, MI\n",
    "\n",
    "# First we select just MI and dedupe rows, because each city has multiple zip codes attached to it.\n",
    "deduped = zips.loc['MI'].drop('zips', axis=1).drop_duplicates()\n",
    "\n",
    "# Select just the features we want to pass to PCA. Also get the colors for each city.\n",
    "x = deduped.iloc[:,:6]\n",
    "x_colors = cmap(deduped['n_sim'])\n",
    "\n",
    "# Run PCA with 3 components\n",
    "pca = PCA(n_components=3).fit_transform(x)\n",
    "\n",
    "# Make the plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca[:,0], pca[:,1], pca[:,2], c=x_colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
